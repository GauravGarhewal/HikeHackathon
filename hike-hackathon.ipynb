{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv', 'user_features.csv', 'train.csv', 'sample_submission_only_headers.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils import resample\n",
    "from sklearn import metrics\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hike1 = pd.read_csv('../input/train.csv')\n",
    "hike2 = pd.read_csv('../input/user_features.csv')\n",
    "hike1_1=hike1[hike1.is_chat == 1].head(10000)\n",
    "hike1_0=hike1[hike1.is_chat ==0].head(10000)\n",
    "hike1= pd.concat([hike1_1,hike1_0], axis=0)\n",
    "hike1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hike2.columns = ['node1_id', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10',\n",
    "       'f11', 'f12', 'f13']\n",
    "hike = hike1.merge(hike2, on='node1_id')\n",
    "hike.columns = ['node1_id', 'node2_id', 'is_chat', 'f1_1', 'f2_1', 'f3_1', 'f4_1', 'f5_1', 'f6_1',\n",
    "       'f7_1', 'f8_1', 'f9_1', 'f10_1', 'f11_1', 'f12_1', 'f13_1']\n",
    "hike2.columns = ['node2_id', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10',\n",
    "       'f11', 'f12', 'f13']\n",
    "hikedf = hike.merge(hike2, on='node2_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hikedf['f1'] = (hikedf['f1']+4*hikedf['f1_1'])/5\n",
    "hikedf['f2'] = (hikedf['f2']+4*hikedf['f2_1'])/5\n",
    "hikedf['f3'] = (hikedf['f3']+4*hikedf['f3_1'])/5\n",
    "hikedf['f4'] = (hikedf['f4']+4*hikedf['f4_1'])/5\n",
    "hikedf['f5'] = (hikedf['f5']+4*hikedf['f5_1'])/5\n",
    "hikedf['f6'] = (hikedf['f6']+4*hikedf['f6_1'])/5\n",
    "hikedf['f7'] = (hikedf['f7']+4*hikedf['f7_1'])/5\n",
    "hikedf['f8'] = (hikedf['f8']+4*hikedf['f8_1'])/5\n",
    "hikedf['f9'] = (hikedf['f9']+4*hikedf['f9_1'])/5\n",
    "hikedf['f10'] = (hikedf['f10']+4*hikedf['f10_1'])/5\n",
    "hikedf['f11'] = (hikedf['f11']+4*hikedf['f11_1'])/5\n",
    "hikedf['f12'] = (hikedf['f12']+4*hikedf['f12_1'])/5\n",
    "hikedf['f13'] = (hikedf['f13']+4*hikedf['f13_1'])/5\n",
    "\n",
    "hikedf.drop(['f1_1', 'f2_1', 'f3_1', 'f4_1',\n",
    "       'f5_1', 'f6_1', 'f7_1', 'f8_1', 'f9_1', 'f10_1', 'f11_1', 'f12_1',\n",
    "       'f13_1'], axis=1, inplace=True)\n",
    "\n",
    "x= hikedf.drop(['node1_id', 'node2_id', 'is_chat'], axis=1)\n",
    "y= hikedf.is_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x_std = sc.fit_transform(x)\n",
    "x_split, x_test, y_split, y_test = train_test_split(x,y,test_size=0.2, random_state=100) \n",
    "x_train, x_val, y_train, y_val = train_test_split(x_split,y_split,test_size=0.2, random_state=100)\n",
    "x_train_std = sc.transform(x_train)\n",
    "x_test_std = sc.transform(x_test)\n",
    "x_val_std = sc.transform(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Logistic Regression model is 67.92 per cent\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train,y_train)\n",
    "print('The accuracy score for Logistic Regression model is %1.2f per cent' %((logreg.score(x_test,y_test))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 29}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knncl = KNeighborsClassifier()\n",
    "param= {'n_neighbors': range(1,30)}\n",
    "knngrid = GridSearchCV(knncl, param_grid= param, cv=5)\n",
    "knngrid.fit(x_val_std,y_val) #for distance based model we use standardize values\n",
    "knngrid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for KNN Classifier model is 71.00 per cent\n"
     ]
    }
   ],
   "source": [
    "knncl = KNeighborsClassifier(n_neighbors=29)\n",
    "knncl.fit(x_train_std,y_train)\n",
    "print('The accuracy score for KNN Classifier model is %1.2f per cent' %((knncl.score(x_test_std,y_test))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtcl = DecisionTreeClassifier()\n",
    "params= {'max_depth': np.arange(1,30)}\n",
    "dtgrid= GridSearchCV(dtcl,params,cv=5)\n",
    "dtgrid.fit(x_val,y_val)\n",
    "dtgrid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Decision Tree model is 70.58 per cent\n"
     ]
    }
   ],
   "source": [
    "dtcl = DecisionTreeClassifier(max_depth=3)\n",
    "dtcl.fit(x_train, y_train)\n",
    "print('The accuracy score for Decision Tree model is %1.2f per cent' %((dtcl.score(x_test,y_test)*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Gaussian Naive Bayes model is 67.07 per cent\n"
     ]
    }
   ],
   "source": [
    "gnbcl = GaussianNB()\n",
    "gnbcl.fit(x_train, y_train)\n",
    "print('The accuracy score for Gaussian Naive Bayes model is %1.2f per cent' %((gnbcl.score(x_test,y_test)*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Multinominal Naive Bayes model is 67.45 per cent\n"
     ]
    }
   ],
   "source": [
    "mncl = MultinomialNB()\n",
    "mncl.fit(x_train, y_train)\n",
    "print('The accuracy score for Multinominal Naive Bayes model is %1.2f per cent' %((mncl.score(x_test,y_test)*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 73}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfcl = RandomForestClassifier()\n",
    "param = {'n_estimators': sp_randint(1, 80)}\n",
    "randomCV = RandomizedSearchCV(rfcl, param_distributions=param, n_iter=80)\n",
    "randomCV.fit(x_val,y_val)\n",
    "randomCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Random Forest model is 71.80 per cent\n"
     ]
    }
   ],
   "source": [
    "rfcl = RandomForestClassifier(n_estimators=70)\n",
    "rfcl.fit(x_train, y_train)\n",
    "print('The accuracy score for Random Forest model is %1.2f per cent' %((rfcl.score(x_test,y_test)*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 71}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgcl = BaggingClassifier()\n",
    "param = {'n_estimators': sp_randint(1, 80)}\n",
    "randomCV = RandomizedSearchCV(bgcl, param_distributions=param, n_iter=80)\n",
    "randomCV.fit(x_val,y_val)\n",
    "randomCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Bagging Classifier model is 71.28 per cent\n"
     ]
    }
   ],
   "source": [
    "bgcl = BaggingClassifier(n_estimators=72)\n",
    "bgcl.fit(x_train, y_train)\n",
    "print('The accuracy score for Bagging Classifier model is %1.2f per cent' %((bgcl.score(x_test,y_test)*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 58}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abcl = AdaBoostClassifier()\n",
    "param = {'n_estimators': sp_randint(1, 80)}\n",
    "randomCV = RandomizedSearchCV(abcl, param_distributions=param, n_iter=80)\n",
    "randomCV.fit(x_val,y_val)\n",
    "randomCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Adaptive Boosting model is 73.08 per cent\n"
     ]
    }
   ],
   "source": [
    "abcl = AdaBoostClassifier(n_estimators=62)\n",
    "abcl.fit(x_train, y_train)\n",
    "print('The accuracy score for Adaptive Boosting model is %1.2f per cent' %((abcl.score(x_test,y_test)*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 68}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbcl = GradientBoostingClassifier()\n",
    "param = {'n_estimators': sp_randint(1, 80)}\n",
    "randomCV = RandomizedSearchCV(gbcl, param_distributions=param, n_iter=80)\n",
    "randomCV.fit(x_val,y_val)\n",
    "randomCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Gradient Boosting model is 73.25 per cent\n"
     ]
    }
   ],
   "source": [
    "gbcl = GradientBoostingClassifier(n_estimators = 57)\n",
    "gbcl.fit(x_train,y_train)\n",
    "print('The accuracy score for Gradient Boosting model is %1.2f per cent' %((gbcl.score(x_test,y_test)*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 69}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgcl = xgb.XGBClassifier()\n",
    "param = {'n_estimators': sp_randint(1, 80)}\n",
    "randomCV = RandomizedSearchCV(xgcl, param_distributions=param, n_iter=80)\n",
    "randomCV.fit(x_val,y_val)\n",
    "randomCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for XG Boost model is 73.65 per cent\n"
     ]
    }
   ],
   "source": [
    "xgcl = xgb.XGBClassifier(n_estimators=56)\n",
    "xgcl.fit(x_train, y_train)\n",
    "print('The accuracy score for XG Boost model is %1.2f per cent' %((xgcl.score(x_test,y_test)*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vocl = VotingClassifier(estimators = [('RandomForest', rfcl),('Bagging Classifier', bgcl),('Gradient Boosting',gbcl), \n",
    "                                      ('XG Boost Classifier',xgcl), ('Ada Boosting',abcl)]\n",
    "                       , voting='soft')\n",
    "#vocl.fit(x_train,y_train)\n",
    "#print('The accuracy of voting model is : %1.4f' %vocl.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This VotingClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-99442d602cf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/voting_classifier.py\u001b[0m in \u001b[0;36m_predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    251\u001b[0m             raise AttributeError(\"predict_proba is not available when\"\n\u001b[1;32m    252\u001b[0m                                  \" voting=%r\" % self.voting)\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         avg = np.average(self._collect_probas(X), axis=0,\n\u001b[1;32m    255\u001b[0m                          weights=self._weights_not_none)\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This VotingClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "y_pred = vocl.predict_proba(x_test)\n",
    "\n",
    "fpr,tpr,thr = metrics.roc_curve(y_test,y_pred[:,1])\n",
    "roc_auc = metrics.auc(fpr,tpr)\n",
    "\n",
    "print(roc_auc)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]\n",
    "models.append(('Logistic Regression', logreg))\n",
    "models.append(('Naive Bayes     ', gnbcl))\n",
    "models.append(('Mutinominal NB   ', mncl))\n",
    "models.append(('KNeighbour      ',knncl))\n",
    "models.append(('Decision Tree     ',dtcl))\n",
    "models.append(('Random Forest   ', rfcl))\n",
    "models.append(('Bagging Classifier', bgcl))\n",
    "models.append(('Ada Boosting     ',abcl))\n",
    "models.append(('Gradient Boosting',gbcl))\n",
    "models.append(('XG Boost Classifier',xgcl))\n",
    "models.append(('Voting Classifier ',vocl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\t 0.678200 (0.008310)\n",
      "Naive Bayes     :\t 0.665900 (0.009672)\n",
      "Mutinominal NB   :\t 0.680450 (0.009986)\n",
      "KNeighbour      :\t 0.706300 (0.007969)\n",
      "Decision Tree     :\t 0.704050 (0.009438)\n",
      "Random Forest   :\t 0.709900 (0.008817)\n",
      "Bagging Classifier:\t 0.712250 (0.009852)\n",
      "Ada Boosting     :\t 0.724800 (0.010565)\n",
      "Gradient Boosting:\t 0.729000 (0.010867)\n",
      "XG Boost Classifier:\t 0.728600 (0.009828)\n",
      "Voting Classifier :\t 0.731150 (0.009105)\n"
     ]
    }
   ],
   "source": [
    "results= []\n",
    "names= []\n",
    "\n",
    "for name,model in models:\n",
    "    kfold= model_selection.KFold(n_splits = 10, random_state=2, shuffle=True)\n",
    "    cv_results = model_selection.cross_val_score(model, x, y, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s:\\t %f (%f)\" %(name,cv_results.mean(),cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/test.csv')\n",
    "\n",
    "hike2.columns = ['node1_id', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10',\n",
    "       'f11', 'f12', 'f13']\n",
    "test1 = test.merge(hike2, on='node1_id')\n",
    "\n",
    "test1.columns = ['id','node1_id', 'node2_id', 'f1_1', 'f2_1', 'f3_1', 'f4_1', 'f5_1', 'f6_1',\n",
    "       'f7_1', 'f8_1', 'f9_1', 'f10_1', 'f11_1', 'f12_1', 'f13_1']\n",
    "\n",
    "hike2.columns = ['node2_id', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10',\n",
    "       'f11', 'f12', 'f13']\n",
    "\n",
    "testdf = test1.merge(hike2, on='node2_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf['f1'] = (testdf['f1']+4*testdf['f1_1'])/5\n",
    "testdf['f2'] = (testdf['f2']+4*testdf['f2_1'])/5\n",
    "testdf['f3'] = (testdf['f3']+4*testdf['f3_1'])/5\n",
    "testdf['f4'] = (testdf['f4']+4*testdf['f4_1'])/5\n",
    "testdf['f5'] = (testdf['f5']+4*testdf['f5_1'])/5\n",
    "testdf['f6'] = (testdf['f6']+4*testdf['f6_1'])/5\n",
    "testdf['f7'] = (testdf['f7']+4*testdf['f7_1'])/5\n",
    "testdf['f8'] = (testdf['f8']+4*testdf['f8_1'])/5\n",
    "testdf['f9'] = (testdf['f9']+4*testdf['f9_1'])/5\n",
    "testdf['f10'] = (testdf['f10']+4*testdf['f10_1'])/5\n",
    "testdf['f11'] = (testdf['f11']+4*testdf['f11_1'])/5\n",
    "testdf['f12'] = (testdf['f12']+4*testdf['f12_1'])/5\n",
    "testdf['f13'] = (testdf['f13']+4*testdf['f13_1'])/5\n",
    "\n",
    "testdf.drop(['f1_1', 'f2_1', 'f3_1', 'f4_1',\n",
    "       'f5_1', 'f6_1', 'f7_1', 'f8_1', 'f9_1', 'f10_1', 'f11_1', 'f12_1',\n",
    "       'f13_1'], axis=1, inplace=True)\n",
    "\n",
    "idn = testdf.id\n",
    "test = testdf.drop(['id','node1_id','node2_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgcl.fit(x,y)\n",
    "pred = xgcl.predict_proba(test)\n",
    "output = pd.DataFrame({'id': idn, 'is_chat': pred[:,1]})\n",
    "output.sort_values('id',inplace=True)\n",
    "output.to_csv('XG_Boost_Balanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbcl.fit(x,y)\n",
    "pred = gbcl.predict_proba(test)\n",
    "output = pd.DataFrame({'id': idn, 'is_chat': pred[:,1]})\n",
    "output.sort_values('id',inplace=True)\n",
    "output.to_csv('Gradient_Boost_Balanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocl.fit(x,y)\n",
    "pred = vocl.predict_proba(test)\n",
    "output = pd.DataFrame({'id': idn, 'is_chat': pred[:,1]})\n",
    "output.sort_values('id',inplace=True)\n",
    "output.to_csv('Voting_Balanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcl.fit(x,y)\n",
    "pred = abcl.predict_proba(test)\n",
    "output = pd.DataFrame({'id': idn, 'is_chat': pred[:,1]})\n",
    "output.sort_values('id',inplace=True)\n",
    "output.to_csv('Ada_Boost_Balanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcl.fit(x,y)\n",
    "pred = rfcl.predict_proba(test)\n",
    "output = pd.DataFrame({'id': idn, 'is_chat': pred[:,1]})\n",
    "output.sort_values('id',inplace=True)\n",
    "output.to_csv('Random_Forest_Balanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgcl.fit(x,y)\n",
    "pred = bgcl.predict_proba(test)\n",
    "output = pd.DataFrame({'id': idn, 'is_chat': pred[:,1]})\n",
    "output.sort_values('id',inplace=True)\n",
    "output.to_csv('Bagging_Balanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
